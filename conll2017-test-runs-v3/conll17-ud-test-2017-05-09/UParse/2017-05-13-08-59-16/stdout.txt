/home/UParse/parser/scripts/run.sh -i /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09 -o /tmp/UParse/2017-05-13-08-59-16/output


/media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09
/tmp/UParse/2017-05-13-08-59-16/output
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6002411
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 15965
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_German"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_German/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_German/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5611271
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 14426
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 190
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Finnish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 185
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Finnish/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Finnish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4901191
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 12390
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Bokmaal"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Bokmaal/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Norwegian-Bokmaal"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Bokmaal/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Bokmaal/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Norwegian-Bokmaal/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Norwegian-Bokmaal/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Norwegian-Bokmaal/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Norwegian-Bokmaal/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Norwegian-Bokmaal/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Norwegian-Bokmaal/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
cnt = 90 * 20 = 1800
cnt = 95 * 20 = 1900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 22051551
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 30
  nvocab : 69260
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 155
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Germanic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Germanic/train"
  dropout : 0.35
  fineTuneFactor : 1
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Germanic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 done!
cnt = 5 * 30 = 150
cnt = 10 * 30 = 300
cnt = 15 * 30 = 450
cnt = 20 * 30 = 600
cnt = 25 * 30 = 750
cnt = 30 * 30 = 900
cnt = 35 * 30 = 1050
cnt = 40 * 30 = 1200
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6227031
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 16818
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_French"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_French/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_French/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 774291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 2
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/vocab.t7"
  feat_dims : "10,30"
  seqLen : 155
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Czech"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : "delex"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Czech/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Czech/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(680 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1215237
load classifier from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4138451
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9875
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_English"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_English/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_English/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 18937991
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 58562
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Czech"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Czech/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Czech/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 18937991
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 58562
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Czech"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Czech/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Czech/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
cnt = 90 * 20 = 1800
cnt = 95 * 20 = 1900
cnt = 100 * 20 = 2000
cnt = 105 * 20 = 2100
cnt = 110 * 20 = 2200
cnt = 115 * 20 = 2300
cnt = 120 * 20 = 2400
cnt = 125 * 20 = 2500
cnt = 130 * 20 = 2600
cnt = 135 * 20 = 2700
cnt = 140 * 20 = 2800
cnt = 145 * 20 = 2900
cnt = 150 * 20 = 3000
cnt = 155 * 20 = 3100
cnt = 160 * 20 = 3200
cnt = 165 * 20 = 3300
cnt = 170 * 20 = 3400
cnt = 175 * 20 = 3500
cnt = 180 * 20 = 3600
cnt = 185 * 20 = 3700
cnt = 190 * 20 = 3800
cnt = 195 * 20 = 3900
cnt = 200 * 20 = 4000
cnt = 205 * 20 = 4100
cnt = 210 * 20 = 4200
cnt = 215 * 20 = 4300
cnt = 220 * 20 = 4400
cnt = 225 * 20 = 4500
cnt = 230 * 20 = 4600
cnt = 235 * 20 = 4700
cnt = 240 * 20 = 4800
cnt = 245 * 20 = 4900
cnt = 250 * 20 = 5000
cnt = 255 * 20 = 5100
cnt = 260 * 20 = 5200
cnt = 265 * 20 = 5300
cnt = 270 * 20 = 5400
cnt = 275 * 20 = 5500
cnt = 280 * 20 = 5600
cnt = 285 * 20 = 5700
cnt = 290 * 20 = 5800
cnt = 295 * 20 = 5900
cnt = 300 * 20 = 6000
cnt = 305 * 20 = 6100
cnt = 310 * 20 = 6200
cnt = 315 * 20 = 6300
cnt = 320 * 20 = 6400
cnt = 325 * 20 = 6500
cnt = 330 * 20 = 6600
cnt = 335 * 20 = 6700
cnt = 340 * 20 = 6800
cnt = 345 * 20 = 6900
cnt = 350 * 20 = 7000
cnt = 355 * 20 = 7100
cnt = 360 * 20 = 7200
cnt = 365 * 20 = 7300
cnt = 370 * 20 = 7400
cnt = 375 * 20 = 7500
cnt = 380 * 20 = 7600
cnt = 385 * 20 = 7700
cnt = 390 * 20 = 7800
cnt = 395 * 20 = 7900
cnt = 400 * 20 = 8000
cnt = 405 * 20 = 8100
cnt = 410 * 20 = 8200
cnt = 415 * 20 = 8300
cnt = 420 * 20 = 8400
cnt = 425 * 20 = 8500
cnt = 430 * 20 = 8600
cnt = 435 * 20 = 8700
cnt = 440 * 20 = 8800
cnt = 445 * 20 = 8900
cnt = 450 * 20 = 9000
cnt = 455 * 20 = 9100
cnt = 460 * 20 = 9200
cnt = 465 * 20 = 9300
cnt = 470 * 20 = 9400
cnt = 475 * 20 = 9500
cnt = 480 * 20 = 9600
cnt = 485 * 20 = 9700
cnt = 490 * 20 = 9800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 51403471
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 35
  nvocab : 165741
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Slavic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Slavic/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 155
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Slavic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Slavic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Slavic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Slavic/train"
  dropout : 0.35
  fineTuneFactor : 1
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Slavic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Slavic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Slavic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Slavic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Slavic/model_0.001.tune.t7 done!
cnt = 5 * 35 = 175
cnt = 10 * 35 = 350
cnt = 15 * 35 = 525
cnt = 20 * 35 = 700
cnt = 25 * 35 = 875
cnt = 30 * 35 = 1050
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2260631
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 3558
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Greek"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Greek"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Greek/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Greek/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Greek/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Greek/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Greek/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Greek/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Greek/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Greek/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Greek/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3312271
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 7300
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Indonesian"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30"
  seqLen : 155
  seed : 123
  feats : "we,pos"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Indonesian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Indonesian/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Indonesian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Indonesian/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Indonesian/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Indonesian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Indonesian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Indonesian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1260 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1679237
load classifier from /home/UParse/parser/conll2017_models/UD_Indonesian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Indonesian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3643651
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 7987
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Latin"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Latin/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Latin/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Latin/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Latin/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Latin/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Latin/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5194611
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 13367
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Italian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Italian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Italian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6002411
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 15965
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_German"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_German/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_German/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_German/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_German/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3301031
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 7098
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Chinese"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Chinese"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Chinese/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Chinese/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Chinese/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Chinese/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Chinese/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Chinese/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Chinese/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Chinese/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Chinese/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3890071
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9226
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Japanese"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese/vocab.t7"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Japanese/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Japanese/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1260 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1679237
load classifier from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4830531
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 12159
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Nynorsk"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Nynorsk/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Norwegian-Nynorsk"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Nynorsk/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Norwegian-Nynorsk/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Norwegian-Nynorsk/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Norwegian-Nynorsk/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Norwegian-Nynorsk/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Norwegian-Nynorsk/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Norwegian-Nynorsk/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Norwegian-Nynorsk/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 11438591
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 33534
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Classic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Classic/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Classic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Classic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Classic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Classic/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Classic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5611271
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 14426
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 190
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Finnish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 185
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Finnish/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Finnish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Finnish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4058691
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9367
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Slovenian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Slovenian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Slovenian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Slovenian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Slovenian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Slovenian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Slovenian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5194611
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 13367
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Italian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Italian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Italian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Italian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Italian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 774291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 2
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Persian-DEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Persian-DEL/vocab.t7"
  feat_dims : "10,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Persian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Persian-DEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Persian-DEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : "delex"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Persian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Persian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Persian-DEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Persian-DEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(680 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1215237
load classifier from /home/UParse/parser/conll2017_models/Persian-DEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Persian-DEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 9986051
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 15
  nvocab : 28632
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hungarian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hungarian/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 180
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Hungarian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hungarian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 178
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hungarian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Hungarian/train"
  dropout : 0.35
  fineTuneFactor : 1
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Hungarian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Hungarian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Hungarian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Hungarian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Hungarian/model_0.001.tune.t7 done!
cnt = 5 * 15 = 75
cnt = 10 * 15 = 150
cnt = 15 * 15 = 225
cnt = 20 * 15 = 300
cnt = 25 * 15 = 375
cnt = 30 * 15 = 450
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4652071
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 11542
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 185
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Portuguese"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 180
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Portuguese/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Portuguese/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5254711
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 13342
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Croatian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Croatian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Croatian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Croatian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Croatian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Croatian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Croatian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Croatian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Croatian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Croatian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Croatian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3178091
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 6557
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Russian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Russian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Russian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2673971
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 5011
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Galician"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Galician/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Galician/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Galician/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Galician/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Galician/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Galician/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4138451
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9875
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_English"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_English/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_English/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
Parse using DeNse, using model UD_German
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/de-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Finnish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fi_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Norwegian-Bokmaal
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/no_bokmaal-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Germanic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/sv-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_French
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fr-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Czech-DEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ga-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_English
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/en_partut-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Czech
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/cs_cltt-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Czech
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/cs-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Slavic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/sk-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Greek
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/el-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Indonesian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/id-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Latin
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/la-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Italian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/it_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_German
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/de_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Chinese
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/zh-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Japanese
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ja_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Norwegian-Nynorsk
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/no_nynorsk-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Classic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/got-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Finnish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fi-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Slovenian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/sl-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Italian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/it-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Persian-DEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/kmr-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Hungarian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/hu-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Portuguese
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/pt_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Croatian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/hr-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Russian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ru_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Galician
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/gl-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_English
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/en-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Danish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/da-udpipe.conlluforward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2812031
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 5440
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Danish"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Danish/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Danish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Danish/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Danish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Danish/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Danish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Danish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Danish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Danish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Danish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2410271
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 3904
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Turkish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Turkish/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Turkish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2255191
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 3474
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latvian"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 170
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Latvian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latvian/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 165
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latvian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latvian/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Latvian/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Latvian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Latvian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Latvian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Latvian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Latvian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4138451
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9875
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_English"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_English/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_English/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_English/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6807091
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 18727
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Spanish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Spanish/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Spanish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4652071
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 11542
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 185
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Portuguese"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 180
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Portuguese/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Portuguese/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Portuguese/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 774291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 2
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/vocab.t7"
  feat_dims : "10,30"
  seqLen : 155
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Czech"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : "delex"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Czech/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Czech/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(680 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1215237
load classifier from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4294431
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 10140
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian-SST"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian-SST/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Slovenian-SST"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian-SST/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Slovenian-SST/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Slovenian-SST/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Slovenian-SST/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Slovenian-SST/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Slovenian-SST/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Slovenian-SST/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Slovenian-SST/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 774291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 2
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Finnic-DEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Finnic-DEL/vocab.t7"
  feat_dims : "10,30"
  seqLen : 180
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Finnic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Finnic-DEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 178
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Finnic-DEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : "delex"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Finnic/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Finnic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Finnic-DEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Finnic-DEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(680 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1215237
load classifier from /home/UParse/parser/conll2017_models/Finnic-DEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Finnic-DEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5099431
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 12998
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Romanian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Romanian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Romanian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Romanian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Romanian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Romanian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Romanian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Romanian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Romanian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Romanian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Romanian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4952191
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 12604
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese-BR"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese-BR/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 185
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Portuguese-BR"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese-BR/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 180
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Portuguese-BR/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Portuguese-BR/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Portuguese-BR/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Portuguese-BR/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Portuguese-BR/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Portuguese-BR/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Portuguese-BR/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6227031
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 16818
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_French"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_French/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_French/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3300871
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 6898
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-ITTB"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-ITTB/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Latin-ITTB"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-ITTB/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-ITTB/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Latin-ITTB/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Latin-ITTB/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Latin-ITTB/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Latin-ITTB/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Latin-ITTB/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Latin-ITTB/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2410271
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 3904
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Turkish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Turkish/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Turkish/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Turkish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Turkish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4160511
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9764
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-PROIEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-PROIEL/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Latin-PROIEL"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-PROIEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Latin-PROIEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Latin-PROIEL/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Latin-PROIEL/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Latin-PROIEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Latin-PROIEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Latin-PROIEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Latin-PROIEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4125531
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9665
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Hindi"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Hindi/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Hindi/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3251531
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 6909
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Persian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Persian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Persian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Persian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Persian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Persian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Persian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Persian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Persian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Persian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Persian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 22051551
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 30
  nvocab : 69260
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 155
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Germanic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Germanic/train"
  dropout : 0.35
  fineTuneFactor : 1
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Germanic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 done!
cnt = 5 * 30 = 150
cnt = 10 * 30 = 300
cnt = 15 * 30 = 450
cnt = 20 * 30 = 600
cnt = 25 * 30 = 750
cnt = 30 * 30 = 900
cnt = 35 * 30 = 1050
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5983291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 15997
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Catalan"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Catalan/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Catalan"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Catalan/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Catalan/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Catalan/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Catalan/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Catalan/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Catalan/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Catalan/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Catalan/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
cnt = 90 * 20 = 1800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 9392151
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 10
  nvocab : 26774
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Estonian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Estonian/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 180
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Estonian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Estonian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 178
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Estonian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Estonian/train"
  dropout : 0.35
  fineTuneFactor : 1
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Estonian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Estonian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Estonian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Estonian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Estonian/model_0.001.tune.t7 done!
cnt = 5 * 10 = 50
cnt = 10 * 10 = 100
cnt = 15 * 10 = 150
cnt = 20 * 10 = 200
cnt = 25 * 10 = 250
cnt = 30 * 10 = 300
cnt = 35 * 10 = 350
cnt = 40 * 10 = 400
cnt = 45 * 10 = 450
cnt = 50 * 10 = 500
cnt = 55 * 10 = 550
cnt = 60 * 10 = 600
cnt = 65 * 10 = 650
cnt = 70 * 10 = 700
cnt = 75 * 10 = 750
cnt = 80 * 10 = 800
cnt = 85 * 10 = 850
cnt = 90 * 10 = 900
cnt = 95 * 10 = 950
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 774291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 2
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL/vocab.t7"
  feat_dims : "10,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Turkic-DEL"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : "delex"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Turkic-DEL/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Turkic-DEL/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(680 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1215237
load classifier from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2907751
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 5574
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Polish"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Polish/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Polish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Polish/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Polish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Polish/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Polish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Polish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Polish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Polish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Polish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5167151
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 13244
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 205
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Arabic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 200
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Arabic/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Arabic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3644651
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 8129
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hebrew"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hebrew/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Hebrew"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hebrew/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hebrew/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Hebrew/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Hebrew/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Hebrew/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Hebrew/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Hebrew/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Hebrew/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2881651
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 5663
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician-TreeGal"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician-TreeGal/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Galician-TreeGal"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician-TreeGal/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Galician-TreeGal/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Galician-TreeGal/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Galician-TreeGal/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Galician-TreeGal/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Galician-TreeGal/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Galician-TreeGal/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Galician-TreeGal/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3890071
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9226
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Japanese"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Japanese/vocab.t7"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Japanese/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Japanese/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1260 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1679237
load classifier from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Japanese/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4727151
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 11640
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek-PROIEL"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Ancient_Greek-PROIEL"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek-PROIEL/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek-PROIEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek-PROIEL/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Ancient_Greek-PROIEL/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Ancient_Greek-PROIEL/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Ancient_Greek-PROIEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Ancient_Greek-PROIEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Ancient_Greek-PROIEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Ancient_Greek-PROIEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 10000831
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 28996
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech-CAC"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech-CAC/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 205
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Czech-CAC"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech-CAC/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 200
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech-CAC/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Czech-CAC/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Czech-CAC/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Czech-CAC/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Czech-CAC/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Czech-CAC/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Czech-CAC/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4449531
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 10581
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish-FTB"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish-FTB/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 190
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Finnish-FTB"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish-FTB/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 185
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Finnish-FTB/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Finnish-FTB/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Finnish-FTB/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Finnish-FTB/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Finnish-FTB/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Finnish-FTB/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Finnish-FTB/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
cnt = 90 * 20 = 1800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2273211
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 3641
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French-Sequoia"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French-Sequoia/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_French-Sequoia"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French-Sequoia/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French-Sequoia/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_French-Sequoia/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_French-Sequoia/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_French-Sequoia/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_French-Sequoia/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_French-Sequoia/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_French-Sequoia/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400

Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Turkish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/tr-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Latvian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/lv-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_English
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/en_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Spanish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/es_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Portuguese
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/pt-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Czech-DEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/hsb-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Slovenian-SST
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/sl_sst-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Finnic-DEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/sme-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Romanian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ro-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Portuguese-BR
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/pt_br-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_French
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fr_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Latin-ITTB
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/la_ittb-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Turkish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/tr_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Latin-PROIEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/la_proiel-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Hindi
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/hi-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Persian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fa-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Germanic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/sv_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Catalan
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ca-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Estonian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/et-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Turkic-DEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/kk-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Polish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/pl-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Arabic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ar_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Hebrew
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/he-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Galician-TreeGal
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/gl_treegal-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Japanese
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ja-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Ancient_Greek-PROIEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/grc_proiel-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Czech-CAC
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/cs_cac-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Finnish-FTB
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fi_ftb-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_French-Sequoia
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fr_sequoia-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using modelforward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2831731
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 5355
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Urdu"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Urdu/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Urdu"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Urdu/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Urdu/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Urdu/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Urdu/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Urdu/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Urdu/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Urdu/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Urdu/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6807091
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 18727
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Spanish"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Spanish/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Spanish/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Spanish/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3161771
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 6485
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Basque"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Basque"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Basque/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Basque/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Basque/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Basque/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Basque/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Basque/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Basque/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Basque/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Basque/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
cnt = 90 * 20 = 1800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4125531
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9665
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Hindi"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Hindi/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Hindi/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Hindi/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Hindi/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 1645771
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 1745
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Vietnamese"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Vietnamese"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Vietnamese/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Vietnamese/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Vietnamese/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Vietnamese/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Vietnamese/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Vietnamese/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Vietnamese/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1260 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1679237
load classifier from /home/UParse/parser/conll2017_models/UD_Vietnamese/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Vietnamese/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4103151
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 9684
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Bulgarian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Bulgarian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Bulgarian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Bulgarian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Bulgarian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Bulgarian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Bulgarian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Bulgarian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Bulgarian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Bulgarian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Bulgarian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2718871
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 5322
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Korean"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Korean"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Korean/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Korean/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Korean/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Korean/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Korean/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Korean/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Korean/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1260 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1679237
load classifier from /home/UParse/parser/conll2017_models/UD_Korean/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Korean/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 18937991
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 58562
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Czech"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Czech/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Czech/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Czech/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Czech/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 774291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 2
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/vocab.t7"
  feat_dims : "10,30"
  seqLen : 155
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Czech"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Czech-DEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : "delex"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Czech/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Czech/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(680 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1215237
load classifier from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Czech-DEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2080171
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 3193
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English-LinES"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English-LinES/vocab.t7"
  feat_dims : "300,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_English-LinES"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English-LinES/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_English-LinES/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_English-LinES/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_English-LinES/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_English-LinES/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_English-LinES/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1260 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1679237
load classifier from /home/UParse/parser/conll2017_models/UD_English-LinES/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_English-LinES/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6863451
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 18925
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish-AnCora"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish-AnCora/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Spanish-AnCora"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish-AnCora/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Spanish-AnCora/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Spanish-AnCora/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Spanish-AnCora/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Spanish-AnCora/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Spanish-AnCora/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Spanish-AnCora/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Spanish-AnCora/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 11438591
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 33534
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Classic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Classic/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Classic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Classic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Classic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Classic/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Classic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Classic/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 22051551
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 30
  nvocab : 69260
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 155
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Germanic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Germanic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Germanic/train"
  dropout : 0.35
  fineTuneFactor : 1
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Germanic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Germanic/model_0.001.tune.t7 done!
cnt = 5 * 30 = 150
cnt = 10 * 30 = 300
cnt = 15 * 30 = 450
cnt = 20 * 30 = 600
cnt = 25 * 30 = 750
cnt = 30 * 30 = 900
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 2815591
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 5474
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch-LassySmall"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch-LassySmall/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Dutch-LassySmall"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch-LassySmall/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch-LassySmall/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Dutch-LassySmall/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Dutch-LassySmall/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Dutch-LassySmall/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Dutch-LassySmall/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Dutch-LassySmall/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Dutch-LassySmall/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 774291
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 2
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL/vocab.t7"
  feat_dims : "10,30"
  seqLen : 150
  seed : 123
  feats : "we,pos"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/Turkic-DEL"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/Turkic-DEL/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : "delex"
  embedOption : "init"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/Turkic-DEL/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/Turkic-DEL/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(680 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1215237
load classifier from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/Turkic-DEL/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4778951
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 11858
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  evalType : "conllx"
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek"
  patience : 1
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  disableEearlyStopping : false
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  ignoreCase : false
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Ancient_Greek"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek/model_0.001.tune.t7"
  lrDiv : 0
  optimMethod : "SGD"
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ancient_Greek/vocab.t7"
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  recDropout : 0.1
  train : "/home/s1459234/data/conll2017_data/UD_Ancient_Greek/train"
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Ancient_Greek/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  dropout : 0.35
  savePerEpoch : false
}
load from /home/UParse/parser/conll2017_models/UD_Ancient_Greek/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Ancient_Greek/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Ancient_Greek/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Ancient_Greek/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 15583711
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 47892
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian-SynTagRus"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian-SynTagRus/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Russian-SynTagRus"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian-SynTagRus/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian-SynTagRus/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Russian-SynTagRus/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Russian-SynTagRus/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Russian-SynTagRus/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Russian-SynTagRus/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Russian-SynTagRus/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Russian-SynTagRus/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
cnt = 35 * 20 = 700
cnt = 40 * 20 = 800
cnt = 45 * 20 = 900
cnt = 50 * 20 = 1000
cnt = 55 * 20 = 1100
cnt = 60 * 20 = 1200
cnt = 65 * 20 = 1300
cnt = 70 * 20 = 1400
cnt = 75 * 20 = 1500
cnt = 80 * 20 = 1600
cnt = 85 * 20 = 1700
cnt = 90 * 20 = 1800
cnt = 95 * 20 = 1900
cnt = 100 * 20 = 2000
cnt = 105 * 20 = 2100
cnt = 110 * 20 = 2200
cnt = 115 * 20 = 2300
cnt = 120 * 20 = 2400
cnt = 125 * 20 = 2500
cnt = 130 * 20 = 2600
cnt = 135 * 20 = 2700
cnt = 140 * 20 = 2800
cnt = 145 * 20 = 2900
cnt = 150 * 20 = 3000
cnt = 155 * 20 = 3100
cnt = 160 * 20 = 3200
cnt = 165 * 20 = 3300
cnt = 170 * 20 = 3400
cnt = 175 * 20 = 3500
cnt = 180 * 20 = 3600
cnt = 185 * 20 = 3700
cnt = 190 * 20 = 3800
cnt = 195 * 20 = 3900
cnt = 200 * 20 = 4000
cnt = 205 * 20 = 4100
cnt = 210 * 20 = 4200
cnt = 215 * 20 = 4300
cnt = 220 * 20 = 4400
cnt = 225 * 20 = 4500
cnt = 230 * 20 = 4600
cnt = 235 * 20 = 4700
cnt = 240 * 20 = 4800
cnt = 245 * 20 = 4900
cnt = 250 * 20 = 5000
cnt = 255 * 20 = 5100
cnt = 260 * 20 = 5200
cnt = 265 * 20 = 5300
cnt = 270 * 20 = 5400
cnt = 275 * 20 = 5500
cnt = 280 * 20 = 5600
cnt = 285 * 20 = 5700
cnt = 290 * 20 = 5800
cnt = 295 * 20 = 5900
cnt = 300 * 20 = 6000
cnt = 305 * 20 = 6100
cnt = 310 * 20 = 6200
cnt = 315 * 20 = 6300
cnt = 320 * 20 = 6400
cnt = 325 * 20 = 6500
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 4207411
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 10055
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Dutch"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Dutch/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Dutch/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Dutch/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Dutch/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Dutch/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Dutch/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Dutch/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 51674831
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 40
  nvocab : 166534
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ukrainian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 32
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ukrainian/vocab.t7"
  feat_dims : "300,30,10,40"
  seqLen : 155
  seed : 123
  feats : "we,pos,lid,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/multi/UD_Ukrainian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ukrainian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 150
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Ukrainian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/multi/UD_Ukrainian/train"
  dropout : 0.35
  fineTuneFactor : 1
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/multi/UD_Ukrainian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Ukrainian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Ukrainian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1360 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1759237
load classifier from /home/UParse/parser/conll2017_models/UD_Ukrainian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Ukrainian/model_0.001.tune.t7 done!
cnt = 5 * 40 = 200
cnt = 10 * 40 = 400
cnt = 15 * 40 = 600
cnt = 20 * 40 = 800
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 6227031
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 16818
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_French"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_French/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_French/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_French/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_French/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 5167151
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 13244
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 205
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Arabic"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 200
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Arabic/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Arabic/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Arabic/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Arabic/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
forward_ lstm layer 1, dropout = 0.350000
lstm [forward_1], RECURRENT dropout = 0.100000
forward_ lstm layer 2, dropout = 0.350000
lstm [forward_2], RECURRENT dropout = 0.100000
backward_ lstm layer 1, dropout = 0.350000
lstm [backward_1], RECURRENT dropout = 0.100000
backward_ lstm layer 2, dropout = 0.350000
lstm [backward_2], RECURRENT dropout = 0.100000
[SelectNetRich] create forward and backward LSTM done!
[SelectNetRich] create attention model done!
[combine_selectnet_parameters] found backward_lookup! backward_lookup	
[combine_selectnet_parameters] found backward_lookup! backward_pos_lookup	
[SelectNetRich] #params 3178091
[SelectNetRich] forward lstm and backward lstm share parameters
[SelectNetRich] clone model done!
{
  minLR : 1e-07
  curLR : 0.001
  batchSize : 20
  nvocab : 6557
  minImprovement : 1.001
  model : "SelectNetPos"
  useGPU : false
  recDropout : 0.1
  test : ""
  modelDir : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian"
  lrDiv : 0
  nlayers : 2
  maxNVocab : 0
  validBatchSize : 20
  vocabFile : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian/vocab.t7"
  feat_dims : "300,30,40"
  seqLen : 150
  seed : 123
  feats : "we,pos,xfeats"
  savePerEpoch : false
  evalType : "conllx"
  freqCut : 1
  wordEmbedding : ""
  dataDir : "/home/s1459234/data/conll2017_data/UD_Russian"
  save : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian/model_0.001.tune.t7"
  optimMethod : "SGD"
  disableEearlyStopping : false
  maxTrainLen : 145
  load : "/home/s1459234/parser/dense_parser/conll2017_models/UD_Russian/model_0.001.dp0.35.r0.1.bs20.t7"
  initRange : 0.1
  modelType : ""
  embedOption : "fineTune"
  saveBeforeLrDiv : false
  gradClip : 5
  nhid : 150
  lr : 0.001
  train : "/home/s1459234/data/conll2017_data/UD_Russian/train"
  dropout : 0.35
  fineTuneFactor : 0
  maxEpoch : 10
  valid : "/home/s1459234/data/conll2017_data/UD_Russian/dev"
  uDVocab : "/home/s1459234/parser/dense_parser/vocab"
  ignoreCase : false
  patience : 1
}
load from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 ...
load from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 done!
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Dropout(0.050000)
  (2): nn.Linear(1340 -> 800)
  (3): nn.ReLU
  (4): nn.Dropout(0.200000)
  (5): nn.Linear(800 -> 800)
  (6): nn.ReLU
  (7): nn.Dropout(0.200000)
  (8): nn.Linear(800 -> 37)
  (9): nn.LogSoftMax
}
#param 1743237
load classifier from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 ...
load classifier from /home/UParse/parser/conll2017_models/UD_Russian/model_0.001.tune.t7 done!
cnt = 5 * 20 = 100
cnt = 10 * 20 = 200
cnt = 15 * 20 = 300
cnt = 20 * 20 = 400
cnt = 25 * 20 = 500
cnt = 30 * 20 = 600
 UD_Urdu
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ur-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Spanish
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/es-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Basque
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/eu-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Hindi
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/hi_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Vietnamese
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/vi-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Bulgarian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/bg-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Korean
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ko-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Czech
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/cs_pud-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Czech-DEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/bxr-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_English-LinES
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/en_lines-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Spanish-AnCora
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/es_ancora-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Classic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/cu-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Germanic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/sv_lines-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Dutch-LassySmall
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/nl_lassysmall-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model Turkic-DEL
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ug-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Ancient_Greek
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/grc-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Russian-SynTagRus
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ru_syntagrus-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Dutch
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/nl-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Ukrainian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/uk-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_French
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/fr_partut-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Arabic
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ar-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
Parse using DeNse, using model UD_Russian
Preprocess input...
Finished preprocessing!
Parse preprocessed file of: /media/test-datasets/universal-dependency-learning/conll17-ud-test-2017-05-09/ru-udpipe.conllu
Finished parsing!
Post-process output..
Finished post-processing!
